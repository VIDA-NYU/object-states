DATASET:
  ROOT: /datasets/Milly_pred
  VIDEO_PATTERN: /datasets/Milly/data/*_pv.mp4
  STEPS_CSV: /datasets/Milly_full.csv
  # EMBEDDING_DIR: /datasets/Milly_pred/embeddings/detections_tracker
  STATES_CSV: /datasets/PTG Object State Labels - Step Annotations.csv
  # STATES_CSV: /datasets/PTG Object State Labels - Simple Step Annotations.csv
  # STATES_CSV: /datasets/PTG Object State Labels - Super Simple Step Annotations.csv
  META_CSV: /datasets/PTG Object State Labels - Metadata.csv
  STATES_CSVS:
    super_simple: /datasets/PTG Object State Labels - Super Simple Step Annotations.csv
    full: /datasets/PTG Object State Labels - Step Annotations.csv

  N_AUGMENTATIONS: 10
  EMBED_SKIP: 5

DATA:
  VOCAB: []
  UNTRACKED_VOCAB: []

  STEP_STAGES:
    pre: [0, 0.15]
    mid: [0.3, 0.7]
    post: [0.85, 1]
    full: [0, 1]

EVAL:
  DETECTION_NAME: '*'
  EMBEDDING_TYPES: ['clip', 'detic', 'detic_s0', 'detic_s1', 'detic_s2']


DETIC: 
  CONFIDENCE: 0.5
  # DETECT_EVERY: 30
  DETECT_EVERY_SECS: 1

EGOHOS:
  DETECT_EVERY: 0.5

XMEM:
  FRAME_SIZE: 420
  CONFIG: {
    'top_k': 15,
    'mem_every': 30,
    'deep_update_every': -1,
    'enable_long_term': True,
    'enable_long_term_count_usage': True,
    'num_prototypes': 64,
    'min_mid_term_frames': 6,
    'max_mid_term_frames': 12,
    'max_long_term_elements': 1000,
    'tentative_frames': 4,
    'tentative_age': 3,
    'max_age': 60,  # in steps
    # 'min_iou': 0.3,
  }
